{"cells":[{"cell_type":"markdown","metadata":{"id":"vKN0km00oXKc"},"source":["# PDIOT ML"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2139,"status":"ok","timestamp":1700527933648,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"},"user_tz":0},"id":"9YEi5xAuojTp","outputId":"d7d77fc0-7a09-4eaf-b50d-f4943d0828eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Khuxf3JZo17Q","executionInfo":{"status":"ok","timestamp":1700527933648,"user_tz":0,"elapsed":5,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"}}},"outputs":[],"source":["import os\n","path = \"/content/drive/MyDrive/Colab Notebooks/pdiot-ml\"\n","os.chdir(path)\n","\n","task_index = 1 # action\n","# task_index = 21 # stationary action\n","# task_index = 221 # 22x repiratory type\n","# task_index = 31 # stationary action\n","# task_index = 32 # repiratory type and other\n","# task_index = 4 # increase case 32 with gyro and accl\n","# task_index = 5 # one model for all\n","\n","# sensor = 'thingy'\n","sensor = 'respeck'\n","\n","# tainable = False\n","tainable = True\n","\n","window_size = 50  # Define the size of the window\n","stride = 1  # Define the stride of the window\n","\n","match task_index:\n","    case 4:\n","        # norm the gyro data\n","        tag = f'accl_gyro_norm'\n","    case 5:\n","        # norm the gyro data\n","        tag = \"accl_gyro_norm\"\n","    case _:\n","        tag = f'accl_only_no_norm'\n","\n","model_path = f'model/model_{sensor}_{tag}_task_{task_index}_{window_size}.h5'\n","data_folder = \"pdiot-data/updated_anonymized_dataset_2023/Respeck\"\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1FS13O9ICnGG","executionInfo":{"status":"ok","timestamp":1700527941016,"user_tz":0,"elapsed":7372,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import concurrent.futures\n","\n","# Read multiple CSV files and label them\n","# data_folder = \"pdiot-data/updated_anonymized_dataset_2023/Thingy\"\n","files = []\n","for folder_name in os.listdir(data_folder):\n","    if folder_name == \".gitkeep\":\n","        continue\n","    files += [(os.path.join(data_folder, folder_name), file_name) for file_name in os.listdir(os.path.join(data_folder, folder_name))]\n","\n","data_list = []\n","labels = []\n","\n","label_action_dict = {\n","    \"ascending\": \"ascending stairs\",\n","    \"descending\": \"descending stairs\",\n","    \"lyingRight\": \"lying down on right\",\n","    \"lyingLeft\": \"lying down on left\",\n","    \"lyingBack\": \"lying down on back\",\n","    \"lyingStomach\": \"lying down on stomach\",\n","    \"miscMovement\": \"miscellaneous movements\",\n","    \"shuffleWalking\": \"shuffle walking\",\n","    \"normalWalking\": \"normal walking\",\n","    \"sitting\": \"sitting/standing\",\n","    \"standing\": \"sitting/standing\"\n","}\n","\n","label_type_dict = {\n","    \"breathingNormal\": \"normal\",\n","}\n","\n","\n","def process_file(file_path, file_name, task_index, label_action_dict, label_type_dict):\n","    if file_name.endswith('.csv'):\n","        df = pd.read_csv(os.path.join(file_path, file_name))\n","\n","        label_action, label_type = file_name.replace('.csv', '').split(\"_\")[2:4]\n","        label_action = label_action_dict[label_action] if label_action in label_action_dict.keys() else label_action\n","        label_type = label_type_dict[label_type] if label_type in label_type_dict.keys() else label_type\n","\n","        match task_index:\n","            case 1:\n","                if label_type not in [\"normal\"]:\n","                    return None, None\n","                label = label_action\n","            case 21:\n","                if label_action in [\"normal walking\", \"ascending stairs\", \"descending stairs\", \"shuffle walking\", \"running\", \"miscellaneous movements\"]:\n","                    return None, None\n","                if label_type not in [\"normal\", \"coughing\", \"hyperventilating\"]:\n","                    return None, None\n","                label = label_action\n","            case 221:\n","                if label_action in [\"normal walking\", \"ascending stairs\", \"descending stairs\", \"shuffle walking\", \"running\", \"miscellaneous movements\"]:\n","                    return None, None\n","                if label_action != \"sitting/standing\":\n","                    return None, None\n","                if label_type not in [\"normal\", \"coughing\", \"hyperventilating\"]:\n","                    return None, None\n","                label = label_type\n","            case 222:\n","                if label_action in [\"normal walking\", \"ascending stairs\", \"descending stairs\", \"shuffle walking\", \"running\", \"miscellaneous movements\"]:\n","                    return None, None\n","                if label_action != \"lying down on left\":\n","                    return None, None\n","                if label_type not in [\"normal\", \"coughing\", \"hyperventilating\"]:\n","                    return None, None\n","                label = label_type\n","            case 223:\n","                if label_action in [\"normal walking\", \"ascending stairs\", \"descending stairs\", \"shuffle walking\", \"running\", \"miscellaneous movements\"]:\n","                    return None, None\n","                if label_action != \"lying down on back\":\n","                    return None, None\n","                if label_type not in [\"normal\", \"coughing\", \"hyperventilating\"]:\n","                    return None, None\n","                label = label_type\n","            case 224:\n","                if label_action in [\"normal walking\", \"ascending stairs\", \"descending stairs\", \"shuffle walking\", \"running\", \"miscellaneous movements\"]:\n","                    return None, None\n","                if label_action != \"lying down on stomach\":\n","                    return None, None\n","                if label_type not in [\"normal\", \"coughing\", \"hyperventilating\"]:\n","                    return None, None\n","                label = label_type\n","            case 225:\n","                if label_action in [\"normal walking\", \"ascending stairs\", \"descending stairs\", \"shuffle walking\", \"running\", \"miscellaneous movements\"]:\n","                    return None, None\n","                if label_action != \"lying down on right\":\n","                    return None, None\n","                if label_type not in [\"normal\", \"coughing\", \"hyperventilating\"]:\n","                    return None, None\n","                label = label_type\n","            case 31:\n","                if label_action in [\"normal walking\", \"ascending stairs\", \"descending stairs\", \"shuffle walking\", \"running\", \"miscellaneous movements\"]:\n","                    return None, None\n","                if label_type in [\"talking\", \"eating\", \"singing\", \"laughing\"]:\n","                    label_type = \"other\"\n","                label = label_action\n","            case 32:\n","                if label_action in [\"normal walking\", \"ascending stairs\", \"descending stairs\", \"shuffle walking\", \"running\", \"miscellaneous movements\"]:\n","                    return None, None\n","                if label_type in [\"talking\", \"eating\", \"singing\", \"laughing\"]:\n","                    label_type = \"other\"\n","                label = label_type\n","            case 4:\n","                # increase case 3\n","                if label_action in [\"normal walking\", \"ascending stairs\", \"descending stairs\", \"shuffle walking\", \"running\", \"miscellaneous movements\"]:\n","                    return None, None\n","                if label_type in [\"talking\", \"eating\", \"singing\", \"laughing\"]:\n","                    label_type = \"other\"\n","                label = \" \".join([label_action, label_type])\n","\n","            case 5:\n","                # if label_type in [\"coughing\", \"hyperventilating\"]:\n","                #     label_type = \"abnormal\"\n","                # if label_type in [\"talking\", \"eating\", \"singing\", \"laughing\"]:\n","                #     label_type = \"other\"\n","                label = \" \".join([label_action, label_type])\n","\n","        match task_index:\n","            case 4:\n","                data = df[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n","            case 5:\n","                data = df[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n","            case _:\n","                data = df[['accel_x', 'accel_y', 'accel_z']]\n","\n","        return label, data\n","\n","    return None, None"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"xA_y4sH8o-Dp","executionInfo":{"status":"ok","timestamp":1700527953447,"user_tz":0,"elapsed":12435,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"}}},"outputs":[],"source":["# Using ThreadPoolExecutor for parallel processing\n","with concurrent.futures.ThreadPoolExecutor() as executor:\n","    future_to_file = {executor.submit(process_file, file_path, file_name, task_index, label_action_dict, label_type_dict): (file_path, file_name) for file_path, file_name in files}\n","\n","    for future in concurrent.futures.as_completed(future_to_file):\n","        file_path, file_name = future_to_file[future]\n","        try:\n","            label, data = future.result()\n","            if label is not None and data is not None:\n","                labels.append(label)\n","                data_list.append(data)\n","        except Exception as exc:\n","            print(f'{file_path}/{file_name} generated an exception: {exc}')\n","\n","\n","# # Stand the accel data\n","# tag += \"_stand\"\n","# for i in range(len(data_list)):\n","#     for col in ['accel_x', 'accel_y', 'accel_z']:\n","#         data_list[i][col] = (data_list[i][col] - data_list[i][col].mean()) / data_list[i][col].std()\n","\n","\n","match task_index:\n","    case 4:\n","        # norm the gyro data\n","        for i in range(len(data_list)):\n","            for col in ['gyro_x', 'gyro_y', 'gyro_z']:\n","                # https://pdf1.alldatasheet.com/datasheet-pdf/view/678850/AD/ADXRS300_15.html\n","                min_val = -300\n","                max_val = 300\n","\n","                data_list[i][col] = (data_list[i][col] - min_val) / (max_val - min_val)\n","    case 5:\n","        # norm the gyro data\n","        for i in range(len(data_list)):\n","            for col in ['gyro_x', 'gyro_y', 'gyro_z']:\n","                # https://pdf1.alldatasheet.com/datasheet-pdf/view/678850/AD/ADXRS300_15.html\n","                min_val = -300\n","                max_val = 300\n","\n","                data_list[i][col] = (data_list[i][col] - min_val) / (max_val - min_val)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"m2lRiS2Dt-IJ","executionInfo":{"status":"ok","timestamp":1700527953448,"user_tz":0,"elapsed":29,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from scipy.signal import spectrogram\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","\n","import random\n","\n","def augment_data(data_list, labels):\n","    augmented_data = []\n","    augmented_labels = []\n","\n","    for index, data in enumerate(data_list):\n","        # Add original data and label\n","        augmented_data.append(data)\n","        augmented_labels.append(labels[index])\n","\n","        # # Add a random number to each column for augmentation\n","        # augmented_data_item = data.copy()\n","        # for column in augmented_data_item.columns:\n","        #     mean_val = augmented_data_item[column].mean()\n","        #     deviation = mean_val * 0.01  # 1% of mean\n","        #     random_shift = random.uniform(-deviation, deviation)\n","        #     augmented_data_item[column] += random_shift\n","\n","        # # Add augmented data and label\n","        # augmented_data.append(augmented_data_item)\n","        # augmented_labels.append(labels[index])  # Same label for augmented data\n","\n","    return augmented_data, augmented_labels\n","\n","# Split the augmented data list and labels into training and test sets\n","data_train, data_temp, labels_train, labels_temp = train_test_split(\n","    data_list, labels, test_size=0.3, random_state=42)\n","\n","data_test, data_val, labels_test, labels_val = train_test_split(\n","    data_temp, labels_temp, test_size=0.3, random_state=42)\n","\n","# Apply data augmentation\n","data_train, labels_train = augment_data(data_train, labels_train)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"fyv5OA9YhF48","executionInfo":{"status":"ok","timestamp":1700527975231,"user_tz":0,"elapsed":21810,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"}}},"outputs":[],"source":["def compute_spectrograms_and_augment_single(sequence, label, window_size, stride, sampling_times):\n","    X_spectrograms = []\n","    y_spectrograms = []\n","\n","    # Original data processing\n","    for j in range(0, len(sequence) - window_size, stride):\n","        window = sequence.iloc[j:j + window_size]\n","        X_spectrograms.append(window)\n","        y_spectrograms.append(label)\n","\n","    # Data augmentation\n","    for _ in range(sampling_times):\n","        # Select a random sampling ratio between 0.8 and 1.2\n","        sampling_ratio = random.uniform(0.8, 1.2)\n","        new_length = int(len(sequence) * sampling_ratio)\n","\n","        # Handle DataFrame sequence\n","        augmented_sequence = pd.DataFrame(index=np.linspace(0, len(sequence) - 1, new_length))\n","        for column in sequence.columns:\n","            interpolated = np.interp(\n","                augmented_sequence.index,\n","                sequence.index,\n","                sequence[column]\n","            )\n","            augmented_sequence[column] = interpolated\n","\n","\n","        # # Calculate new indices for linear interpolation\n","        # new_indices = np.linspace(0, len(sequence) - 1, new_length)\n","\n","        # # Initialize augmented sequence DataFrame\n","        # augmented_sequence = pd.DataFrame(index=new_indices)\n","\n","        # # Efficient linear interpolation for each column\n","        # for column in sequence.columns:\n","        #     y_values = sequence[column].values\n","        #     x_values = np.arange(len(y_values))\n","\n","        #     # Calculate slopes for linear interpolation\n","        #     slopes = (y_values[1:] - y_values[:-1]) / (x_values[1:] - x_values[:-1])\n","\n","        #     # Find the index positions in the original data for each new index\n","        #     idx_pos = np.searchsorted(x_values[1:], new_indices)\n","\n","        #     # Calculate the interpolated values\n","        #     interpolated_values = y_values[idx_pos] + slopes[idx_pos] * (new_indices - x_values[idx_pos])\n","\n","        #     augmented_sequence[column] = interpolated_values\n","\n","        # Process the augmented sequence\n","        for j in range(0, len(augmented_sequence) - window_size, stride):\n","            window = augmented_sequence.iloc[j:j + window_size]\n","            X_spectrograms.append(window)\n","            y_spectrograms.append(label)\n","\n","    return X_spectrograms, y_spectrograms\n","\n","import concurrent.futures\n","\n","def process_data_in_parallel(data, labels, window_size, stride, sampling_times):\n","    X_spectrograms_combined = []\n","    y_spectrograms_combined = []\n","\n","    with concurrent.futures.ThreadPoolExecutor() as executor:\n","        futures = [executor.submit(compute_spectrograms_and_augment_single, sequence, label, window_size, stride, sampling_times) for sequence, label in zip(data, labels)]\n","\n","        for future in concurrent.futures.as_completed(futures):\n","            try:\n","                X_spectrograms, y_spectrograms = future.result()\n","                X_spectrograms_combined.extend(X_spectrograms)\n","                y_spectrograms_combined.extend(y_spectrograms)\n","            except Exception as exc:\n","                print(f'An exception occurred: {exc}')\n","\n","    return np.array(X_spectrograms_combined), np.array(y_spectrograms_combined)\n","\n","# Process training and test data in parallel\n","X_train, y_train = process_data_in_parallel(data_train, labels_train, window_size, stride, 0)\n","X_test, y_test = process_data_in_parallel(data_test, labels_test, window_size, stride, 0)\n","X_val, y_val = process_data_in_parallel(data_val, labels_val, window_size, stride, 0)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1700527975231,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"},"user_tz":0},"id":"dxrrDk_EAS96","outputId":"99d0e113-af4e-4c1b-a9ed-bc6131917706"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}],"source":["# Label encode and one-hot encode labels\n","label_encoder = LabelEncoder()\n","integer_encoded_train = label_encoder.fit_transform(y_train)\n","y_train = to_categorical(integer_encoded_train)\n","\n","integer_encoded_test = label_encoder.fit_transform(y_test)\n","y_test = to_categorical(integer_encoded_test)\n","\n","integer_encoded_val = label_encoder.fit_transform(y_val)\n","y_val = to_categorical(integer_encoded_val)\n","\n","integer_mapping = {l: i for i, l in enumerate(label_encoder.classes_)}\n","\n","integer_mapping = {i: l for i, l in enumerate(label_encoder.classes_)}\n","\n","result = False\n","match task_index:\n","    case 1:\n","        result = integer_mapping == {\n","            0: 'ascending stairs',\n","            1: 'descending stairs',\n","            2: 'lying down on back',\n","            3: 'lying down on left',\n","            4: 'lying down on right',\n","            5: 'lying down on stomach',\n","            6: 'miscellaneous movements',\n","            7: 'normal walking',\n","            8: 'running',\n","            9: 'shuffle walking',\n","            10: 'sitting/standing'\n","        }\n","\n","    case 21:\n","        result = integer_mapping == {\n","            0: 'lying down on back',\n","            1: 'lying down on left',\n","            2: 'lying down on right',\n","            3: 'lying down on stomach',\n","            4: 'sitting/standing'\n","        }\n","\n","    case 22:\n","        result = integer_mapping == {\n","            0: 'coughing',\n","            1: 'hyperventilating',\n","            2: 'normal',\n","        }\n","\n","    case 31:\n","        result = integer_mapping == {\n","            0: 'lying down on back',\n","            1: 'lying down on left',\n","            2: 'lying down on right',\n","            3: 'lying down on stomach',\n","            4: 'sitting/standing'\n","        }\n","\n","    case 32:\n","        result = integer_mapping == {\n","            0: 'coughing',\n","            1: 'hyperventilating',\n","            2: 'normal',\n","            3: 'other'\n","        }\n","\n","\n","    case 4:\n","        result = integer_mapping == {\n","            0: 'lying down on back coughing',\n","            1: 'lying down on back hyperventilating',\n","            2: 'lying down on back normal',\n","            3: 'lying down on back other',\n","            4: 'lying down on left coughing',\n","            5: 'lying down on left hyperventilating',\n","            6: 'lying down on left normal',\n","            7: 'lying down on left other',\n","            8: 'lying down on right coughing',\n","            9: 'lying down on right hyperventilating',\n","            10: 'lying down on right normal',\n","            11: 'lying down on right other',\n","            12: 'lying down on stomach coughing',\n","            13: 'lying down on stomach hyperventilating',\n","            14: 'lying down on stomach normal',\n","            15: 'lying down on stomach other',\n","            16: 'sitting/standing coughing',\n","            17: 'sitting/standing hyperventilating',\n","            18: 'sitting/standing normal',\n","            19: 'sitting/standing other'\n","        }\n","\n","    case 5:\n","        result = integer_mapping == {\n","            0: 'ascending stairs normal',\n","            1: 'descending stairs normal',\n","            2: 'lying down on back coughing',\n","            3: 'lying down on back hyperventilating',\n","            4: 'lying down on back laughing',\n","            5: 'lying down on back normal',\n","            6: 'lying down on back singing',\n","            7: 'lying down on back talking',\n","            8: 'lying down on left coughing',\n","            9: 'lying down on left hyperventilating',\n","            10: 'lying down on left laughing',\n","            11: 'lying down on left normal',\n","            12: 'lying down on left singing',\n","            13: 'lying down on left talking',\n","            14: 'lying down on right coughing',\n","            15: 'lying down on right hyperventilating',\n","            16: 'lying down on right laughing',\n","            17: 'lying down on right normal',\n","            18: 'lying down on right singing',\n","            19: 'lying down on right talking',\n","            20: 'lying down on stomach coughing',\n","            21: 'lying down on stomach hyperventilating',\n","            22: 'lying down on stomach laughing',\n","            23: 'lying down on stomach normal',\n","            24: 'lying down on stomach singing',\n","            25: 'lying down on stomach talking',\n","            26: 'miscellaneous movements normal',\n","            27: 'normal walking normal',\n","            28: 'running normal',\n","            29: 'shuffle walking normal',\n","            30: 'sitting/standing coughing',\n","            31: 'sitting/standing eating',\n","            32: 'sitting/standing hyperventilating',\n","            33: 'sitting/standing laughing',\n","            34: 'sitting/standing normal',\n","            35: 'sitting/standing singing',\n","            36: 'sitting/standing talking'\n","        }\n","    case _:\n","        print(integer_mapping)\n","result"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":443,"status":"ok","timestamp":1700527976675,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"},"user_tz":0},"id":"0nAA2h_70bhS","outputId":"aba4c9c1-4a49-46f6-9e0e-c69a7d344a05"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/device:GPU:0']"]},"metadata":{},"execution_count":8}],"source":["import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","\n","def get_available_gpus():\n","    local_device_protos = device_lib.list_local_devices()\n","    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n","get_available_gpus()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Zw_COd7xROQd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700527983845,"user_tz":0,"elapsed":7174,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"}},"outputId":"d4b78c04-b167-4823-a9a8-ed499ddaa9f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kapre in /usr/local/lib/python3.10/dist-packages (0.3.7)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from kapre) (1.23.5)\n","Requirement already satisfied: librosa>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from kapre) (0.10.1)\n","Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from kapre) (2.14.0)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (3.0.1)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (1.11.3)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (1.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (1.3.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (0.58.1)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (0.12.1)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (1.8.0)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (0.3.7)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (4.5.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (0.3)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.7.2->kapre) (1.0.7)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (16.0.6)\n","Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (2.3.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (1.59.2)\n","Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (2.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (2.14.0)\n","Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.0.0->kapre) (2.14.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->kapre) (0.41.3)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.7.2->kapre) (0.41.1)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (4.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.7.2->kapre) (2.31.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa>=0.7.2->kapre) (3.2.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa>=0.7.2->kapre) (1.16.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (3.5.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (3.0.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.7.2->kapre) (2.21)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.7.2->kapre) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow>=2.0.0->kapre) (3.2.2)\n"]}],"source":["!pip install kapre"]},{"cell_type":"code","source":["# import numpy as np\n","# from tensorflow.keras import backend as K\n","# from tensorflow.python.keras.layers import InputSpec, Layer\n","\n","# class Argmax(Layer):\n","#     \"\"\"\n","#     Based on https://github.com/YerevaNN/R-NET-in-Keras/blob/master/layers/Argmax.py\n","#     \"\"\"\n","#     def __init__(self, axis=-1, **kwargs):\n","#         super(Argmax, self).__init__(**kwargs)\n","#         self.supports_masking = True\n","#         self.axis = axis\n","\n","#     def call(self, inputs, mask=None):\n","#         return K.argmax(inputs, axis=self.axis)\n","\n","#     def compute_output_shape(self, input_shape):\n","#         input_shape = np.array(input_shape)\n","#         del input_shape[self.axis]\n","#         return tuple(input_shape)\n","\n","#     def compute_mask(self, x, mask):\n","#         return None\n","\n","#     def get_config(self):\n","#         config = {'axis': self.axis}\n","#         base_config = super(Argmax, self).get_config()\n","#         return dict(np.array(base_config.items()) + np.array(config.items()))"],"metadata":{"id":"A2BDrG0hEjgU","executionInfo":{"status":"ok","timestamp":1700527983845,"user_tz":0,"elapsed":6,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1700527984489,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"},"user_tz":0},"id":"dDoe2WHYq-Hf","outputId":"4fc8f435-ccac-4520-d920-7f68cfc53bc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," stft (STFT)                 (None, 50, 65, 3)         0         \n","                                                                 \n"," magnitude (Magnitude)       (None, 50, 65, 3)         0         \n","                                                                 \n"," magnitude_to_decibel (Magn  (None, 50, 65, 3)         0         \n"," itudeToDecibel)                                                 \n","                                                                 \n"," conv2d (Conv2D)             (None, 46, 61, 16)        1216      \n","                                                                 \n"," dropout (Dropout)           (None, 46, 61, 16)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 42, 57, 32)        12832     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 42, 57, 32)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 38, 53, 32)        25632     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 38, 53, 32)        0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 34, 49, 16)        12816     \n","                                                                 \n"," dropout_3 (Dropout)         (None, 34, 49, 16)        0         \n","                                                                 \n"," flatten (Flatten)           (None, 26656)             0         \n","                                                                 \n"," dense (Dense)               (None, 32)                853024    \n","                                                                 \n"," dropout_4 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 16)                528       \n","                                                                 \n"," dropout_5 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 11)                187       \n","                                                                 \n","=================================================================\n","Total params: 906235 (3.46 MB)\n","Trainable params: 906235 (3.46 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from kapre import STFT, Magnitude, MagnitudeToDecibel\n","from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization, Bidirectional\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Softmax, Reshape, Conv2D, Flatten\n","from tensorflow.keras.models import load_model\n","from keras.regularizers import l1_l2\n","\n","\n","\n","# Load the model\n","\n","if os.path.exists(model_path):\n","    model = load_model(model_path)\n","else:\n","    # Define the input shape for your audio data (e.g., 1D audio signal with a certain sampling rate)\n","    input_shape = (X_train.shape[1], X_train.shape[2])  # Replace with your actual input shape\n","\n","    model = Sequential()\n","\n","    # A STFT layer\n","    model.add(STFT(n_fft=128, win_length=5, hop_length=1,\n","                window_name=None, pad_end=True,\n","                input_data_format='channels_last', output_data_format='channels_last',\n","                input_shape=input_shape))\n","    model.add(Magnitude())\n","    model.add(MagnitudeToDecibel())  # these three layers can be replaced with get_stft_magnitude_layer()\n","    # Alternatively, you may want to use a melspectrogram layer\n","    # melgram_layer = get_melspectrogram_layer()\n","    # or log-frequency layer\n","    # log_stft_layer = get_log_frequency_spectrogram_layer()\n","\n","    model.add(Conv2D(16, 5, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Conv2D(32, 5, activation='relu')) # , padding=\"same\")\n","    model.add(Dropout(0.2))\n","\n","    # model.add(Conv2D(64, 3, activation='relu', padding=\"same\"))\n","    # model.add(Dropout(0.2))\n","\n","    model.add(Conv2D(32, 5, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Conv2D(16, 5, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Flatten())\n","\n","    # model.add(Reshape((window_size, 65 * 32), input_shape=(-1, window_size, 65, 32)))\n","\n","    # # First LSTM layer with Dropout\n","    # model.add(LSTM(256, input_shape = (window_size, 65 * 32), return_sequences=True))\n","    # # model.add(LSTM(256, input_shape = input_shape, return_sequences=True))\n","    # model.add(Dropout(0.2))\n","    # model.add(BatchNormalization())\n","\n","    # # Second LSTM layer with Dropout\n","    # model.add(LSTM(256, return_sequences=True))\n","    # model.add(Dropout(0.2))\n","    # model.add(BatchNormalization())\n","\n","    # # Third LSTM layer with Dropout\n","    # model.add(LSTM(256))\n","    # model.add(Dropout(0.2))\n","    # model.add(BatchNormalization())\n","\n","    # Fully connected layers\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    # Fully connected layers\n","    model.add(Dense(16, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Dense(y_train.shape[1], activation='softmax'))\n","\n","\n","    # # add more layers as you want\n","    # model.add(Conv2D(128, (3, 3), strides=(2, 2)))\n","    # model.add(BatchNormalization())\n","    # model.add(ReLU())\n","    # model.add(GlobalAveragePooling2D())\n","\n","    # model.add(Dense(y_train.shape[1]))\n","    # model.add(Softmax())\n","\n","    # Compile the model\n","\n","    model.summary()\n","\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42563,"status":"ok","timestamp":1700528027050,"user":{"displayName":"Haobo Yang","userId":"12926400958493979541"},"user_tz":0},"id":"MmItd-lPCefr","outputId":"64b3cf92-c4e4-4e1f-ef7e-8f11a793598f"},"outputs":[{"output_type":"stream","name":"stdout","text":["3908/3908 [==============================] - 36s 7ms/step - loss: 2.3944 - accuracy: 0.1008\n","Test Loss: 2.3944480419158936, Test Accuracy: 0.10077091306447983\n"]}],"source":["# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QePXpoA11hzZ","outputId":"a338cc27-423a-444a-b0db-d5b6b236030f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","205/205 [==============================] - 156s 650ms/step - loss: 1.8427 - accuracy: 0.2783 - val_loss: 1.4703 - val_accuracy: 0.3531\n","Epoch 2/100\n","205/205 [==============================] - 130s 634ms/step - loss: 1.4340 - accuracy: 0.3917 - val_loss: 1.2336 - val_accuracy: 0.4641\n","Epoch 3/100\n","205/205 [==============================] - 129s 630ms/step - loss: 1.3340 - accuracy: 0.4668 - val_loss: 1.1903 - val_accuracy: 0.5154\n","Epoch 4/100\n","205/205 [==============================] - 128s 627ms/step - loss: 1.1913 - accuracy: 0.5288 - val_loss: 0.9787 - val_accuracy: 0.6168\n","Epoch 5/100\n","205/205 [==============================] - 127s 620ms/step - loss: 1.0562 - accuracy: 0.5811 - val_loss: 1.0095 - val_accuracy: 0.6008\n","Epoch 6/100\n","205/205 [==============================] - 127s 620ms/step - loss: 0.9974 - accuracy: 0.6043 - val_loss: 0.9767 - val_accuracy: 0.6016\n","Epoch 7/100\n","205/205 [==============================] - 127s 620ms/step - loss: 0.9452 - accuracy: 0.6246 - val_loss: 1.0048 - val_accuracy: 0.6222\n","Epoch 8/100\n","205/205 [==============================] - 129s 629ms/step - loss: 0.8941 - accuracy: 0.6460 - val_loss: 1.0402 - val_accuracy: 0.6267\n","Epoch 9/100\n"," 66/205 [========>.....................] - ETA: 1:24 - loss: 0.8523 - accuracy: 0.6650"]}],"source":["from keras.callbacks import EarlyStopping\n","\n","if tainable:\n","    # Train the model with early stopping\n","    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=512*4, callbacks=[\n","        EarlyStopping(monitor='val_accuracy', patience=10, baseline=0.85, restore_best_weights=True),\n","        # EarlyStopping(monitor='loss', patience=5, baseline=0.1)\n","    ])\n","    # model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=512, callbacks=[\n","    #     EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n","    #     # EarlyStopping(monitor='loss', patience=5, baseline=0.1)\n","    # ])\n","    # model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=16, callbacks=[\n","    #     EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n","    #     # EarlyStopping(monitor='loss', patience=5, baseline=0.1)\n","    # ])\n","\n","    # Evaluate the model\n","    loss, accuracy = model.evaluate(X_test, y_test)\n","    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P0fXXB2nLmDl"},"outputs":[],"source":["from kapre import STFTTflite, MagnitudeTflite\n","\n","if True:\n","    model.save(model_path)\n","\n","    model_tflite = Sequential()\n","\n","    model_tflite.add(STFTTflite(n_fft=128, win_length=5, hop_length=1,\n","                window_name=None, pad_end=True,\n","                input_data_format='channels_last', output_data_format='channels_last',\n","                input_shape=input_shape))\n","    model_tflite.add(MagnitudeTflite())\n","    model_tflite.add(MagnitudeToDecibel())\n","\n","    model_tflite.add(Conv2D(16, 5, activation='relu'))\n","    model_tflite.add(Dropout(0.2))\n","\n","    model_tflite.add(Conv2D(32, 5, activation='relu'))\n","    model_tflite.add(Dropout(0.2))\n","\n","    # model_tflite.add(Conv2D(64, 3, activation='relu', padding=\"same\"))\n","    # model_tflite.add(Dropout(0.2))\n","\n","    model_tflite.add(Conv2D(32, 5, activation='relu'))\n","    model_tflite.add(Dropout(0.2))\n","\n","    model_tflite.add(Conv2D(16, 5, activation='relu'))\n","    model_tflite.add(Dropout(0.2))\n","\n","    model_tflite.add(Flatten())\n","\n","    # model_tflite.add(Reshape((window_size, 65 * 32), input_shape=(-1, window_size, 65, 32)))\n","\n","    # # First LSTM layer with Dropout\n","    # model_tflite.add(LSTM(256, input_shape = (50, 65 * 32), return_sequences=True))\n","    # model_tflite.add(Dropout(0.2))\n","    # model_tflite.add(BatchNormalization())\n","\n","    # # Second LSTM layer with Dropout\n","    # model_tflite.add(LSTM(256, return_sequences=True))\n","    # model_tflite.add(Dropout(0.2))\n","    # model_tflite.add(BatchNormalization())\n","\n","    # # Third LSTM layer with Dropout\n","    # model_tflite.add(LSTM(256))\n","    # model_tflite.add(Dropout(0.2))\n","    # model_tflite.add(BatchNormalization())\n","\n","    # Fully connected layers\n","    model_tflite.add(Dense(32, activation='relu'))\n","    model_tflite.add(Dropout(0.2))\n","\n","    # Fully connected layers\n","    model_tflite.add(Dense(16, activation='relu'))\n","    model_tflite.add(Dropout(0.2))\n","\n","    model_tflite.add(Dense(y_train.shape[1], activation='softmax'))\n","\n","    # load the trained weights into the tflite compatible model.\n","    model_tflite.set_weights(model.get_weights())\n","\n","    # # Save the entire model to a HDF5 file\n","    # run_model = tf.function(lambda x: model_tflite(x))\n","    # # This is important, let's fix the input size.\n","    # concrete_func = run_model.get_concrete_function(\n","    #     tf.TensorSpec((1, X_train.shape[1], X_train.shape[2]), model_tflite.inputs[0].dtype))\n","\n","    # # model directory.\n","    # model_tflite.save('temp', save_format=\"tf\", signatures=concrete_func)\n","    # converter = tf.lite.TFLiteConverter.from_saved_model('temp')\n","\n","    # Convert the model.\n","    converter = tf.lite.TFLiteConverter.from_keras_model(model_tflite)\n","\n","    model_tflite_path = '.'.join([model_path.split('.')[0], 'tflite'])\n","    tflite_model = converter.convert()\n","    open(model_tflite_path, \"wb\").write(tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cir5ucSprE99"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","from scipy import stats\n","from sklearn.preprocessing import LabelEncoder\n","from scipy.signal import spectrogram\n","\n","# Load the model\n","if os.path.exists(model_path):\n","    model = load_model(model_path)\n","\n","# Read and preprocess the new CSV file\n","# new_csv_file = \"/content/drive/MyDrive/Colab Notebooks/pdiot-ml/pdiot-data/test_data/Respeck_s1911593_Sitting_Normal_clean_27-09-2023_14-00-59.csv\"\n","# new_csv_file = \"/content/drive/MyDrive/Colab Notebooks/pdiot-ml/pdiot-data/updated_anonymized_dataset_2023/Respeck/s100/s100_respeck_ascending_breathingNormal.csv\"\n","# new_csv_file = \"/content/drive/MyDrive/Colab Notebooks/pdiot-ml/pdiot-data/updated_anonymized_dataset_2023/Respeck/s100/s100_respeck_sitting_breathingNormal.csv\"\n","new_csv_file = \"/content/drive/MyDrive/Colab Notebooks/pdiot-ml/pdiot-data/updated_anonymized_dataset_2023/Respeck/s100/s100_respeck_sitting_coughing.csv\"\n","# # new_csv_file = \"\"\n","\n","\n","match task_index:\n","    case 4:\n","        new_df = pd.read_csv(new_csv_file)[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n","    case 5:\n","        new_df = pd.read_csv(new_csv_file)[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n","    case _:\n","        new_df = pd.read_csv(new_csv_file)[['accel_x', 'accel_y', 'accel_z']]\n","\n","\n","match task_index:\n","    case 4:\n","        # norm the gyro data\n","        for col in ['gyro_x', 'gyro_y', 'gyro_z']:\n","            # https://pdf1.alldatasheet.com/datasheet-pdf/view/678850/AD/ADXRS300_15.html\n","            min_val = -300\n","            max_val = 300\n","\n","            new_df[col] = (new_df[col] - min_val) / (max_val - min_val)\n","    case 5:\n","        # norm the gyro data\n","        for col in ['gyro_x', 'gyro_y', 'gyro_z']:\n","            # https://pdf1.alldatasheet.com/datasheet-pdf/view/678850/AD/ADXRS300_15.html\n","            min_val = -300\n","            max_val = 300\n","\n","            new_df[col] = (new_df[col] - min_val) / (max_val - min_val)\n","\n","# Window the new sequence\n","window_size = 50  # Define the size of the window\n","stride = 1  # Define the stride of the window\n","\n","new_windows = []\n","new_sequence = new_df.values\n","for j in range(0, len(new_sequence) - window_size, stride):\n","    window = new_sequence[j:j + window_size]\n","\n","    # Compute the spectrogram of the window\n","    # _, _, Sxx = spectrogram(window, axis=0)\n","\n","    # new_windows.append(Sxx)\n","    new_windows.append(window)\n","\n","new_windows = np.array(new_windows)\n","\n","# Make predictions\n","predicted_label_indices = model.predict(new_windows)\n","# predicted_label_indices = np.argmax(predictions, axis=1)\n","\n","print(predicted_label_indices)\n","\n","# Assuming label_encoder is already fitted on the labels during training\n","predicted_labels = label_encoder.inverse_transform(predicted_label_indices)\n","\n","# # Choose the most frequent label as the final prediction using NumPy\n","# unique_labels, counts = np.unique(predicted_labels, return_counts=True)\n","# final_prediction = unique_labels[np.argmax(counts)]\n","\n","print(f\"The predicted label for the new data is: {predicted_labels}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLSebDV-ri7f"},"outputs":[],"source":["from tensorflow.keras.utils import plot_model\n","\n","# Assuming the TensorFlow model is stored in a variable called 'model'\n","# Replace 'model' with your actual model variable if different\n","\n","# Generating the model architecture diagram and saving it as an image\n","plot_model(model, show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kYZNVna2Y3ws"},"outputs":[],"source":["print(model.summary())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tgbGhYFFbGd6"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}